{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation in Excel ---LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "#reading excel\n",
    "df = pd.read_csv('1weather_madrid_LEMD_1997_2015.csv')\n",
    "print(df.head()) #including the Date. \n",
    "\n",
    "print(df.tail()) #7 columns, including the Date. \n",
    "\n",
    "#Separate dates for future plotting\n",
    "train_dates = pd.to_datetime(df['Date'])\n",
    "print(train_dates.tail(15)) #Check last few dates. \n",
    "\n",
    "#Variables for training\n",
    "cols = list(df)[1:3]\n",
    "#Date and volume columns are not used in training. \n",
    "print(cols) #[temperature, humidity]\n",
    "\n",
    "\n",
    "#detect missing values-nothing found\n",
    "df.isna().sum()\n",
    "\n",
    "# temperature distribution\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.distplot(df['Mean TemperatureC'],bins=[i for i in range(0,61,5)], kde=False)\n",
    "plt.title(\"Distribution of Temperatures\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Humidity distribution\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.distplot(df[' Mean Humidity'],bins=[i for i in range(0,61,5)], kde=False)\n",
    "plt.title(\"Distribution of Humidity\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#dataframe division\n",
    "#New dataframe with only training data - mean temperature and humidity for all rows\n",
    "df_for_training = df[cols].astype(float)\n",
    "\n",
    "#LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "##normalize the dataset, both temperature and humidity values between -1 and 1\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training)\n",
    "\n",
    "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. : 2191*14*2\n",
    "#In this example, the n_features is 2. We will make timesteps = 14 (past days data used for training). \n",
    "\n",
    "#Empty lists to be populated using formatted training data\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 14  # Number of past days we want to use to predict the future.\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#for i in range(14, 2191-1+1)\n",
    "#trainx (i-14:i, 0:array[1])\n",
    "#trainy (i+1-1:i+1,0)\n",
    "\n",
    "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "#LSTM\n",
    "#In my case, trainX has a shape (2177, 14, 2). \n",
    "#2177 because we are looking back 14 days (2177 - 14 = 2163). \n",
    "#Remember that we cannot look back 14 days until we get to the 15th day. \n",
    "#Also, trainY has a shape (2177, 1). Our model only predicts a single value, but \n",
    "#it needs multiple variables (5 in my example) to make this prediction. \n",
    "#This is why we can only predict a single day after our training, the day after where our data ends.\n",
    "#To predict more days in future, we need all the 5 variables which we do not have. \n",
    "#We need to predict all variables if we want to do that\n",
    "\n",
    "\n",
    "# define the Autoencoder model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(trainX, trainY, epochs=10, batch_size=16, validation_split=0.1, verbose=1)\n",
    "# Prediction\n",
    "\n",
    "n_future=30\n",
    "n_past=1\n",
    "\n",
    "forecast_period_dates= pd.date_range(list(train_dates)[-n_past], periods=n_future,freq='1d').tolist()\n",
    "\n",
    "#predict_period_dates = pd.date_range(list(train_dates)[-n_past], periods=n_days_for_prediction, freq=us_bd).tolist()\n",
    "\n",
    "\n",
    "forecast=model.predict(trainX[n_future:])\n",
    "forecast_copies=np.repeat(forecast,df_for_training.shape[1], axis=-1)\n",
    "y_pred_future = scaler.inverse_transform(forecast_copies)[:,0]\n",
    "\n",
    "n_future=60\n",
    "n_past = 1\n",
    "n_days_for_prediction=30  #let us predict past 15 days\n",
    "\n",
    "predict_period_dates = pd.date_range(list(train_dates)[-n_past], periods=n_days_for_prediction, freq='1d').tolist()\n",
    "print(predict_period_dates)\n",
    "\n",
    "#Make prediction\n",
    "prediction = model.predict(trainX[-n_days_for_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
    "\n",
    "\n",
    "#Perform inverse transformation to rescale back to original range\n",
    "#Since we used 5 variables for transform, the inverse expects same dimensions\n",
    "#Therefore, let us copy our values 5 times and discard them after inverse transform\n",
    "prediction_copies = np.repeat(prediction, df_for_training.shape[1], axis=-1)\n",
    "y_pred_future = scaler.inverse_transform(prediction_copies)[:,0]\n",
    "\n",
    "\n",
    "# Convert timestamp to date\n",
    "forecast_dates = []\n",
    "for time_i in predict_period_dates:\n",
    "    forecast_dates.append(time_i.date())\n",
    "\n",
    "    \n",
    "df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Temperature':y_pred_future})\n",
    "df_forecast['Date']=pd.to_datetime(df_forecast['Date'])\n",
    "#df_forecast, storing them in excel\n",
    "with pd.ExcelWriter(r'C:\\Users\\i3\\forecastLSTM.xlsx') as writer:\n",
    "    df_forecast.to_excel(writer,sheet_name='df_forecast', index=False)\n",
    "\n",
    "## humidity \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "#data preparation\n",
    "df_h = pd.read_csv('weather_humidity.csv')\n",
    "print(df_h.head()) #7 columns, including the Date.\n",
    "print(df_h.tail()) #7 columns, including the Date.\n",
    "\n",
    "#Separate dates for future plotting\n",
    "train_dates_h = pd.to_datetime(df_h['Date'])\n",
    "print(train_dates_h.tail(15)) #Check last few dates.\n",
    "\n",
    "#Variables for training\n",
    "cols_h = list(df_h)[1:3]\n",
    "#Date and volume columns are not used in training.\n",
    "print(cols_h) #['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "\n",
    "#New dataframe with only training data - mean temperature and humidity for all rows\n",
    "df_for_training_h = df_h[cols_h].astype(float)\n",
    "\n",
    "#LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "# normalize the dataset, both temperature and humidity values between -1 and 1\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training_h)\n",
    "\n",
    "df_for_training_scaled_h = scaler.transform(df_for_training_h)\n",
    "print(\"traning_scaled\",len(df_for_training_scaled_h),df_for_training_scaled_h)\n",
    "\n",
    "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. : 2191*14*2\n",
    "#In this example, the n_features is 2. We will make timesteps = 14 (past days data used for training).\n",
    "\n",
    "#Empty lists to be populated using formatted training data\n",
    "trainX_h = []\n",
    "trainY_h = []\n",
    "\n",
    "n_future_h = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past_h = 14  # Number of past days we want to use to predict the future.\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#for i in range(14, 2191-1+1)\n",
    "#trainx (i-14:i, 0:array[1])\n",
    "#trainy (i+1-1:i+1,0)\n",
    "\n",
    "for i in range(n_past_h, len(df_for_training_scaled_h) - n_future_h +1):\n",
    "    trainX_h.append(df_for_training_scaled_h[i - n_past_h:i, 0:df_for_training_h.shape[1]])\n",
    "    trainY_h.append(df_for_training_scaled_h[i + n_future_h - 1:i + n_future_h, 0])\n",
    "\n",
    "trainX_h, trainY_h = np.array(trainX_h), np.array(trainY_h)\n",
    "\n",
    "trainY_h\n",
    "\n",
    "#print('trainX shape == {}.'.format(trainX.shape))\n",
    "#print('trainY shape == {}.'.format(trainY.shape))\n",
    "#In my example, my df_for_training_scaled has a shape (2177, 14, 6)\n",
    "#2177 refers to the number of data points and 6 refers to the columns (multi-variables).\n",
    "#In my case, trainX has a shape (2177, 14, 2).\n",
    "#2177 because we are looking back 14 days (2177 - 14 = 2163).\n",
    "#Remember that we cannot look back 14 days until we get to the 15th day.\n",
    "#Also, trainY has a shape (2177, 1). Our model only predicts a single value, but\n",
    "#it needs multiple variables (5 in my example) to make this prediction.\n",
    "#This is why we can only predict a single day after our training, the day after where our data ends.\n",
    "#To predict more days in future, we need all the 5 variables which we do not have.\n",
    "#We need to predict all variables if we want to do that\n",
    "\n",
    "# define the Autoencoder model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX_h.shape[1], trainX_h.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY_h.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(trainX_h, trainY_h, epochs=10, batch_size=16, validation_split=0.1, verbose=1)\n",
    "\n",
    "##\n",
    "n_future_h=30\n",
    "n_past_h=1\n",
    "\n",
    "forecast_period_dates_h= pd.date_range(list(train_dates_h)[-n_past_h], periods=n_future_h,freq='1d').tolist()\n",
    "forecast_h=model.predict(trainX_h[n_future_h:])\n",
    "forecast_copies_h=np.repeat(forecast_h,df_for_training_h.shape[1], axis=-1)\n",
    "y_pred_future_h = scaler.inverse_transform(forecast_copies_h)[:,0]\n",
    "\n",
    "\n",
    "n_future_h=60\n",
    "n_past_h = 1\n",
    "n_days_for_prediction_h=30  #let us predict past 15 days\n",
    "\n",
    "predict_period_dates_h = pd.date_range(list(train_dates_h)[-n_past_h], periods=n_days_for_prediction_h, freq='1d').tolist()\n",
    "\n",
    "#Make prediction\n",
    "prediction_h = model.predict(trainX_h[-n_days_for_prediction_h:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
    "#Perform inverse transformation to rescale back to original range\n",
    "#Since we used 5 variables for transform, the inverse expects same dimensions\n",
    "#Therefore, let us copy our values 5 times and discard them after inverse transform\n",
    "prediction_copies_h = np.repeat(prediction_h, df_for_training_h.shape[1], axis=-1)\n",
    "y_pred_future_h = scaler.inverse_transform(prediction_copies_h)[:,0]\n",
    "\n",
    "df_forecast_h = pd.DataFrame({'Date':np.array(predict_period_dates_h), 'Humidity':y_pred_future_h})\n",
    "\n",
    "#df_forecast, storing them in excel\n",
    "with pd.ExcelWriter(r'C:\\Users\\i3\\forecastLSTM_h.xlsx') as writer:\n",
    "    df_forecast_h.to_excel(writer,sheet_name='df_forecast_h', index=False)\n",
    "\n",
    "# comparing forecast with raspberry pi --for Temperature\n",
    "\n",
    "#print(type(df_forecast))\n",
    "df_forecast['Date'] = pd.to_datetime(df_forecast['Date']).dt.date\n",
    "\n",
    "forecast_dict=df_forecast.set_index('Date').T.to_dict('list')\n",
    "##print(forecast_dict)\n",
    "##print(forecast_dict[\"2022-04-30\"])\n",
    "for rec in forecast_dict.keys():\n",
    "    temp=(forecast_dict.get(rec))\n",
    "  #  print(rec,temp[0],type(temp[0]))\n",
    "    \n",
    "df_rasp = pd.read_csv('rasp_input.csv')\n",
    "#print(df_rasp.head()) #7 columns, including the Date.\n",
    "#print(df_rasp.tail()) #7 columns, including the Date.\n",
    "#print(df_rasp['Date'])\n",
    "df_rasp['Date']=pd.to_datetime(df_rasp['Date']).dt.date\n",
    "print(df_rasp)\n",
    "\n",
    "#Variables for training\n",
    "cols = list(df_rasp)[0:2]\n",
    "#Date and temp,humidity columns are not used in training.\n",
    "#print(cols) \n",
    "\n",
    "#New dataframe with only training data - mean temperature and humidity for all rows\n",
    "df_for_rasp = df_rasp[cols]\n",
    "#print(type(df_for_rasp))\n",
    "#print(df_for_rasp)\n",
    "\n",
    "\n",
    "#implementing MAPE-K loop\n",
    "df_for_rasp_dict=df_for_rasp.set_index('Date').T.to_dict('list')\n",
    "#print(df_for_rasp_dict.keys())\n",
    "#print(forecast_dict)\n",
    "open('knowled.csv', 'w').close()\n",
    "import pandas as pd\n",
    "for rec in forecast_dict.keys():\n",
    "    temp=(forecast_dict.get(rec))\n",
    "    if rec in df_for_rasp_dict.keys():\n",
    "        temp2=(df_for_rasp_dict.get(rec))\n",
    "        diff_temp=temp[0]-temp2[0]\n",
    "        print(\"temperature difference observed for: \",diff_temp,rec)\n",
    "        if (diff_temp)!=0 :\n",
    "            #knowledge=pd.DataFrame(['5','4],columns=['date','temperature'])\n",
    "            knowled = pd.DataFrame([[rec, temp2[0]]], columns=['Date', 'Temp'])\n",
    "            #knowledge.to_csv('knowledge.csv',index=False)\n",
    "            knowled.to_csv('knowled.csv',mode='a+', header=False, index=False, encoding=\"utf-16\")\n",
    "            if (diff_temp)<0:\n",
    "                final_temp=temp[0]+abs(diff_temp) ##final_temp has to be passed to  GUI\n",
    "                print(\"predicted temp less than actual rasp,final_temp is: \",final_temp)\n",
    "            else:\n",
    "                final_temp=temp2[0]+diff_temp\n",
    "                print(\"predicted temp greater than actual rasp,final_temp is: \",final_temp)\n",
    "    else:\n",
    "        temp2=['None']\n",
    "  #  print(rec,temp[0],type(temp[0]),temp2[0])\n",
    "print(final_temp)\n",
    "# calculating deviation for humidity\n",
    "print(type(df_forecast_h))\n",
    "df_forecast_h['Date'] = pd.to_datetime(df_forecast_h['Date']).dt.date\n",
    "\n",
    "\n",
    "forecast_dict_h=df_forecast_h.set_index('Date').T.to_dict('list')\n",
    "##print(forecast_dict)\n",
    "##print(forecast_dict[\"2022-04-30\"])\n",
    "for rec in forecast_dict_h.keys():\n",
    "    temp=(forecast_dict_h.get(rec))\n",
    " #   print(rec,temp[0],type(temp[0]))\n",
    "\n",
    "\n",
    "df_rasp = pd.read_csv('rasp_input.csv')\n",
    "#print(df_rasp.head()) #7 columns, including the Date.\n",
    "#print(df_rasp.tail()) #7 columns, including the Date.\n",
    "#print(df_rasp['Date'])\n",
    "df_rasp['Date']=pd.to_datetime(df_rasp['Date']).dt.date\n",
    "#print(df_rasp)\n",
    "\n",
    "#Variables for training\n",
    "#cols = list(df_rasp_h)[0:2]\n",
    "cols = ['Date', 'Humidity']\n",
    "#Date and volume columns are not used in training.\n",
    "#print(cols) \n",
    "\n",
    "#New dataframe with only training data - mean temperature and humidity for all rows\n",
    "df_for_rasp_h = df_rasp[cols]\n",
    "#print(type(df_for_rasp_h))\n",
    "print(df_for_rasp_h)\n",
    "\n",
    "\n",
    "#MAPEK for humidity\n",
    "df_for_rasp_dict_h=df_for_rasp_h.set_index('Date').T.to_dict('list')\n",
    "#print(df_for_rasp_dict_h.keys())\n",
    "#print(forecast_dict)\n",
    "open('knowled_h.csv', 'w').close()\n",
    "import pandas as pd\n",
    "for rec in forecast_dict_h.keys():\n",
    "    temp_h=(forecast_dict_h.get(rec))\n",
    "    if rec in df_for_rasp_dict_h.keys():\n",
    "        temp2_h=(df_for_rasp_dict_h.get(rec))\n",
    "        diff_hum=temp_h[0]-temp2_h[0]\n",
    "        print(\"Humidity difference observed for: \",diff_temp,rec)\n",
    "        if (diff_hum)!=0 :\n",
    "            #knowledge=pd.DataFrame(['5','4],columns=['date','temperature'])\n",
    "            knowled_h = pd.DataFrame([[rec, temp2_h[0]]], columns=['Date', 'Temp'])\n",
    "            #knowledge.to_csv('knowledge.csv',index=False)\n",
    "            knowled_h.to_csv('knowled_h.csv',mode='a', header=False, index=False, encoding=\"utf-16\")\n",
    "            if (diff_hum)<0:\n",
    "                final_hum=temp_h[0]+abs(diff_hum) ##final_temp has to be passed to  GUI\n",
    "                print(\"predicted humidity less than actual sensor value,final Humidity is: \",final_hum)\n",
    "            else:\n",
    "                final_hum=temp2_h[0]+diff_hum\n",
    "                print(\"predicted humidity greater than actual sensor value,final Humidity is: \",final_hum)\n",
    "    else:\n",
    "        temp2_h=['None']\n",
    "   # print(rec,temp_h[0],type(temp_h[0]),temp2_h[0])\n",
    "df_for_rasp\n",
    "print(df_for_rasp_dict_h.keys())\n",
    "print(df_for_rasp_dict.keys())\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "checking_hum\n",
    "checking_hum= df_for_rasp_dict_h[today]\n",
    "print(checking_hum)\n",
    "checking_temp= df_for_rasp_dict[today]\n",
    "print(checking_temp)\n",
    "if ((checking_temp[0]<=17) and (checking_hum[0]<=60)):\n",
    "    myhome=1 #on\n",
    "elif ((checking_temp[0]>=17) and (checking_hum[0]<=60)):\n",
    "    myhome=2 # heater off, water on\n",
    "elif ((checking_temp[0]<=17) and (checking_hum[0]>=60)):\n",
    "    myhome=3 # heater on, water off\n",
    "else:\n",
    "    myhome=4\n",
    "print(myhome)\n",
    "print(myhome)\n",
    "%store myhome\n",
    "checking1_temp1=30\n",
    "checking1_hum1=50\n",
    "if ((checking1_temp1<=17) and (checking1_hum1<=60)):\n",
    "    myhome=1 #on\n",
    "elif ((checking1_temp1>=17) and (checking1_hum1<=60)):\n",
    "    myhome=2 # heater off, water on\n",
    "elif ((checking1_temp1<=17) and (checking1_hum1>=60)):\n",
    "    myhome=3 # heater on, water off\n",
    "else:\n",
    "    myhome=4\n",
    "print(myhome)\n",
    "%store myhome\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
